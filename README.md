# E-commerce Synthetic Data Project (SQLite | Python)

This project demonstrates a complete A-SDLC workflow by generating synthetic e-commerce data, ingesting it into a SQLite database, and running SQL joins across multiple tables.

## ğŸ“Œ Features

- âœ” 5 synthetic e-commerce datasets
- âœ” Automated ingestion into SQLite
- âœ” Clean relational schema with foreign keys
- âœ” Complex SQL joins for reporting
- âœ” Fully reproducible workflow

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ users.csv
â”‚   â”œâ”€â”€ products.csv
â”‚   â”œâ”€â”€ orders.csv
â”‚   â”œâ”€â”€ order_items.csv
â”‚   â””â”€â”€ reviews.csv
â”œâ”€â”€ db/
â”‚   â””â”€â”€ ecommerce.db
â”œâ”€â”€ generate_data.py
â”œâ”€â”€ ingest_to_db.py
â”œâ”€â”€ query.sql
â””â”€â”€ README.md
```

## ğŸ§ª Step 1 â€” Generate Synthetic Data

Run the `generate_data.py` script to create 5 synthetic CSV files in the `/data/` directory.

```bash
python generate_data.py
```

This will generate:
- `users.csv`
- `products.csv`
- `orders.csv`
- `order_items.csv`
- `reviews.csv`

## ğŸ—„ Step 2 â€” Ingest CSV Files Into SQLite

Run the `ingest_to_db.py` script to load the CSV data into a SQLite database.

```bash
python ingest_to_db.py
```

This script:
- Loads all CSVs using `pandas`.
- Creates SQLite tables with a proper schema.
- Enforces foreign key constraints.
- Inserts the data into the tables.
- Verifies the ingestion by printing row counts.

The final database is saved at `/db/ecommerce.db`.

## ğŸ§© Step 3 â€” Run SQL Queries

The `query.sql` file contains two queries for analysis:

1.  **Detailed Order Breakdown**: Joins across `users`, `orders`, `order_items`, and `products` to produce a detailed line-item view.
2.  **Total Spend Per User**: Aggregates all purchases to calculate the total spend for each user.

Run the queries using the `sqlite3` CLI:

```bash
sqlite3 db/ecommerce.db < query.sql
```

## ğŸ“¦ Technologies Used

- Python 3
- Pandas
- SQLite3
- SQL

## ğŸš€ How It Works

1.  **Data Generation**: The `generate_data.py` script creates fake e-commerce data that looks real and maintains relational integrity, simulating a real business database.
2.  **Database Ingestion**: The `ingest_to_db.py` script acts as a data pipeline, moving data from CSV files into a structured SQLite database. It ensures data types are correct and foreign keys are enforced.
3.  **SQL Joins**: The `query.sql` file tests the database by running meaningful business queries, demonstrating an understanding of relational structure, SQL joins, and reporting logic.
4.  **Version Control**: The entire project, including data, scripts, and the database, is version-controlled with Git and available on GitHub.